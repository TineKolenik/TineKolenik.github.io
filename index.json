[{"authors":[],"categories":[],"content":"","date":1537824872,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537824872,"objectID":"499c9e328f2ac4eb30adc2be921cb834","permalink":"https://tinekolenik.github.io/detailed_interests/","publishdate":"2018-09-24T23:34:32+02:00","relpermalink":"/detailed_interests/","section":"","summary":"","tags":[],"title":"Detailed_interests","type":"page"},{"authors":["Kolenik, T."],"categories":null,"content":"","date":1529764199,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529764199,"objectID":"17ff14122398b46ec09b6a995cd3995e","permalink":"https://tinekolenik.github.io/publication/truerperceptions/","publishdate":"2018-06-23T16:29:59+02:00","relpermalink":"/publication/truerperceptions/","section":"publication","summary":"Cognitivism regards the cognitive system as an information-processing machine. Its purpose is to build an isomorphic representation of the outside world through the input and processed information from the environment, which is supposedly knowable to the cognitive system. Evolutionary scientists claim that, consequently, natural selection optimises perception in such a way that the internal representations mirror the outside world more and more accurately. Enactivism, a contemporary non-cognitivist paradigm in cognitive science, rejects the notion that cognition's purpose is the mental reproduction of the outside world through perception. The objective reality is not knowable to the cognitive system according to the paradigm's constructivist presumption. Each organism co-creates its own world through its own perception or the process of knowing – as according to enactivism, perception is inextricable from knowing. This is the consequence of the organism's identity-production based on its own survival needs. In my work, I will research whether veridical or non-veridical perception bears more survival value for an organism. I will do this by testing different agents with a genetic algorithm (GA). The GA will be grounded in philosophical analysis of how different presumptions of different cognitive science paradigms influence research on epistemic questions of the process of knowing the outside world. My overall aims are threefold: 1) to deepen the understanding of how cognition, computation and construction are connected, which will be necessary to build the model, 2) to reveal the influence of presumptions on such research, and 3) to make research on theories of non-veridical perception more credible. According to the previous research by Hoffman et al. [3], whose work was based in cognitivism, I expect for my own computer model, which will be based in enactivism, to show similar results – that certain kinds of non-veridical perception offers more survival value to the modelled organism. Hoffman et al.’s model is presented as evidence in support of authors’ Interface Theory of Perception, which claims that perception is a user interface between an organism and the outside world, fitted to the organism’s fitness and not the objective truth. Hoffman et al.’s model will be reproduced and its presumptions analysed. Then, Hoffman et al.’s cognitivist model’s results will be compared with the results of my enactivist model.","tags":[],"title":"Are truer perceptions really better perceptions? A genetic algorithm study","type":"publication"},{"authors":["Jug, J.","Kolenik, T.","Ofner, A. \u003csub\u003e\u003csup\u003e_(first co-authors)_\u003c/sup\u003e\u003c/sub\u003e","\u0026 Farkaš, I."],"categories":null,"content":"Jug, Kolenik and Ofner are first co-authors\n","date":1527804000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527804000,"objectID":"3462fe67cac8292f836310e7e9b7549e","permalink":"https://tinekolenik.github.io/publication/computational-model-of-enactive-visuospatial-mental-imagery/","publishdate":"2018-06-01T00:00:00+02:00","relpermalink":"/publication/computational-model-of-enactive-visuospatial-mental-imagery/","section":"publication","summary":"From the onset of cognitive revolution, the concept of mental imagery has been given different, many times opposing, theoretical accounts. Mental imagery appears to be a ubiquitous, yet wholly individual, easy to explain experience on the one hand, being hard to deal with scientifically on the other hand. The focus of this research is on an enactive approach to visuospatial mental imagery, inspired by Sima’s perceptual instantiation theory. We designed a hybrid computational model, composed of a forward model, an inverse model, both implemented as neural networks, and a memory/controller module, that grounds simple mental concepts, such as a triangle and a square, in perceptual actions, and is able to reimagine these objects by performing the necessary perceptual actions in a simulated humanoid robot. We tested the model on three tasks – salience-based object recognition, imagination-based object recognition and object imagination – and achieved very good results showing, as a proof of concept, that perceptual actions are a viable candidate for grounding the visuospatial mental concepts as well as the credible substrate of visuospatial mental imagery.","tags":[],"title":"Computational model of enactive visuospatial mental imagery using saccadic perceptual actions","type":"publication"},{"authors":["Kolenik, T."],"categories":null,"content":"","date":1507928259,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1507928259,"objectID":"6ee31b05bb2f97dcb9c2d679fcc236ab","permalink":"https://tinekolenik.github.io/publication/use-ga-nonveridical_perception/","publishdate":"2017-10-13T22:57:39+02:00","relpermalink":"/publication/use-ga-nonveridical_perception/","section":"publication","summary":"Synthetic  approach  to  (cognitive)  science \u0026ndash; researching (cognitive) phenomena with computer and robot models \u0026ndash; has been called upon by various field authorities, such as Froese, Ziemke and Harvey, to tackle the problem of opposing theories that have pestered Western philosophy for centuries, especially those of epistemic nature. One synthetic methodology can offer comparison of such theories under the mechanism of natural selection \u0026ndash; genetic algorithm. Specifically, genetic algorithms can be deployed to research non-veridical perception, the viewpoint held by various paradigms (e.g., constructivism) that the world we experience is not a representation of the world out there. One such theory that boasts empirical proof is the interface theory of perception. However, genetic algorithms, although bearing an ecologically viable modeling platform in the form of natural selection, can be, due to yet undiscovered biological realities, largely manipulated with arbitrarily set parameters and methods to get biased results. What’s more, GA-based research on non-veridical perception does not seem to include full computational, algorithmic and implementational materials. This begs a carefully set protocol for such research.","tags":[],"title":"The Use of Genetic Algorithms in Researching Non-Veridical Perception","type":"publication"},{"authors":["Kolenik, T."],"categories":null,"content":"","date":1480623249,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1480623249,"objectID":"eec5577962b3261633e162bf4dfd1e87","permalink":"https://tinekolenik.github.io/publication/heidegger-in-roomba/","publishdate":"2016-12-01T22:14:09+02:00","relpermalink":"/publication/heidegger-in-roomba/","section":"publication","summary":"Robotski sesalec Roomba ne bi bil mogoč brez bogate zgodovine filozofskega izročila, ki predstavlja temelj klasične umetne inteligence. Načelo slednje je računska metafora za um,kjer je kognicija le manipuliranje arbitrarnih simbolov. A takšna paradigma ima številne težave, kot sta problem okvirja in ozemljitve simbolov. To so razkrile ideje Heideggerja, Merleau-Pontyja idr. kontinetalnih filozofov, ki so skozi robotika Brooksa, izumitelja Roombe, vodile nastanek utelešene umetne inteligence (UUI). UUI temelji na paradigminujnosti spoja agenta in okolja ter vznika kognicije iz senzorimotorične zanke. A raziskovalci na tem področju ponujajo zelo različne interpretacije teh predpostavk. To ponovno prinaša težave, predvsem v obliki vprašanja avtonomije in nastanka pomena. Namen članka je predstaviti vzajemen odnos filozofija-UUI. Filozofijo vzpostavi kot ključno za razvoj (U)UI ter ponuja pregled trenutnih trendov in praktičnih primerov. Članek na koncu prikaže problematičnost sodobnih smernic ter ponudi morebitne rešitve, ki med drugim izvirajo prav iz filozofije.","tags":[],"title":"Kaj imata skupnega Heidegger in Roomba: utelešena umetna inteligenca kot peskovnik kontinentalne filozofije","type":"publication"},{"authors":["Kolenik, T."],"categories":null,"content":"","date":1476391498,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1476391498,"objectID":"7d26fab3daf5c85777798e6dea8199ac","permalink":"https://tinekolenik.github.io/publication/non-trivial-autonomy-is/","publishdate":"2016-10-13T22:44:58+02:00","relpermalink":"/publication/non-trivial-autonomy-is/","section":"publication","summary":"Embodied cognitive robotics has made remarkable advances in modelling natural cognitive processes and thus speculating about the content of the black box of the mind. The field’s tackling of one of the biggest questions in cognitive science, the question of meaning, has been met with considerable acclaim. The latter was gained by modelling the grounding of meaning through an agent's use of language as a cognitive tool in its active interaction with the environment via sensorimotor behavior. Many different approaches with such an agent have been labelled as successful in modelling meaning comprehension, which begs the question of what natural understanding and meaning really are. This points to such embodied cognitive models lacking – their grounding is neither meaningful nor significant to them, and it is not internally necessary, but is rather forced onto them by externally programmed fundamental goals. What is missing is a non-trivial, constitutive autonomy, which would make robots create their own goals in order to self-regulate and preserve their internal organization; in order to survive. Only then can meaning truly be assigned.","tags":[],"title":"Embodied Cognitive Robotics, the Question of Meaning and the Necessity of Non-Trivial Autonomy","type":"publication"},{"authors":["Kolenik, T."],"categories":null,"content":"","date":1466692420,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1466692420,"objectID":"8b0543272b80bc5459ba2af6c3880516","permalink":"https://tinekolenik.github.io/publication/symbolgroundingcogr/","publishdate":"2016-06-23T16:33:40+02:00","relpermalink":"/publication/symbolgroundingcogr/","section":"publication","summary":"The problem of symbol grounding (assigning meanings to symbols) presents a vast impasse in cognitive science. Yet many contemporary theories are based on empirical evidence that argues that grounding happens through an agent's active interaction with the environment via sensorimotor behaviour. To explain how low-level cognitive phenomena lead to high-level cognition, Vygotsky argues that language leads to abstraction and reasoning. This process can be simulated using robotic models. I review three relevant models and present some of the findings here. The models’ basic goal is to learn and name specific actions. Cangelosi et al.’s robot learns and grounds the actions of moving limbs, Farkaš et al.’s “point”, “touch” and “push”, and Lallee et al.’s “give”, “take” and so on. Cangelosi's approach, employing two robots, is based on a teacher-learner relationship, similar to how a child mimics people. It produces grounding transfer, as the robot acquires higher level actions through learning and naming basic actions. However, it has biologically questionable multilayer perceptron and it forces the learner to unnaturally imitate the teacher. Farkaš's model learns, using a biologically viable reward-based system, names an action and comments on it, the latter proving stronger grounded meaning. The shortcomings are in the location-determining visual module and that it can only name an action after executing it, bringing forth the limitations of its understanding. Lallee et al. expand the understanding of an action with a model that sees action as goal-based with a starting and ending state, similar to humans’ perception. The authors argue that an action represents a wider context (e.g. causality, possession). The model learns to divide its actions into subparts which denote the object and the causal relations (if-then, because), resulting in a fuller understanding of actions. However, the model has an innate vocabulary, which hinders its validity. Each model approaches the same fundamental paradigm from its own direction and presents a different, but limited representation of human symbol grounding. Nevertheless, they show promise in creating autonomous, biologically and ecologically viable models that ground meanings through interaction with the environment via low-level cognition, using language to acquire higher cognition.","tags":[],"title":"Symbol grounding through action and language in cognitive robotics","type":"publication"}]